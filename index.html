<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments">
  <meta name="keywords" content="WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>WildGS-SLAM</title>

  <!-- Bootstrap -->
  <link rel="stylesheet" href="./static/css/bootstrap-4.4.1.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  
  
  
  
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/72.png"> -->

  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/app.js"></script>
  <script src="./static/js/video_comparison.js"></script>

  <link rel="stylesheet" href="./static/css/dics.original.css">
  <script src="./static/js/event_handler.js"></script>
  <script src="./static/js/dics.original.js"></script>
  


</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- <h1 class="title is-1 publication-title"><img src="static/images/72.png" width="70"></h1> -->
          <h1 class="title is-1 publication-title">WildGS-SLAM</h1>
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 0">Monocular Gaussian Splatting SLAM in Dynamic Environments</h2>

          <!-- <div class="column is-full_width">
            <h2 class="title is-4">3DV 2024 (Oral, <span style="color:#ff0000;">Best Paper Honorable Mention</span>)</h2>
          </div> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jianhao-zheng.github.io/">Jianhao Zheng</a><sup>1*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                <a href="https://zzh2000.github.io">Zihan Zhu</a><sup>2*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
              <a href="https://openreview.net/profile?id=~Valentin_Bieri1">Valentin Bieri</a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a><sup>1,3</sup>&nbsp;&nbsp;
              <!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->
            </span>
            <!-- <br> -->
            <span class="author-block">
              <a href="https://pengsongyou.github.io">Songyou Peng</a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <!-- <a href="https://zhpcui.github.io/">Zhaopeng Cui</a><sup>2<span>&#8224;</span> </sup>&nbsp;&nbsp;&nbsp;&nbsp; -->
              <a href="https://ir0.github.io/">Iro Armeni</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>

          </div>
          <div class="column is-full_width">
            <h2 class="is-size-6">* Equal Contribution</h2>
            <!-- <h2 class="is-size-6">(* equal contribution)  (<span>&#8224;</span> corresponding author)</h2> -->
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Stanford University</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>ETH ZÃ¼rich</span>&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>Microsoft</span>&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://tbd"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=xXuolzFvddQ&t=11s"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Poster Link. -->
              <!-- <span class="link-block">
                <a href="media/nice-slam/poster_nice-slam.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-palette"></i>
                  </span>
                  <span>Poster</span>
                  </a>
              </span> -->

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/GradientSpaces/WildGS-SLAM.git"
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

  

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" style="margin-top: -3rem;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <video class="video" width="100%" id="xyalias6" loop playsinline autoplay muted src="resources/demo.mp4" onplay="videoPlay(this)" style="height: 0px;"></video>
          <canvas height=0 class="videoMerge" id="xyalias6Merge"></canvas>
      
          <h2 class="subtitle has-text-centered" style="margin-top: 14px">
            TL;DR: We present WildGS-SLAM, a robust monocular RGB SLAM system that uses uncertainty-aware tracking and mapping to handle dynamic scenes, leveraging DINOv2-based uncertainty maps for dynamic object removal, improving tracking, mapping, and enable high-quality view synthesis.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -60px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present WildGS-SLAM, a robust and efficient monocular RGB SLAM system designed to handle dynamic environments by leveraging uncertainty-aware geometric mapping. Unlike traditional SLAM systems, which assume static scenes, our approach integrates depth and uncertainty information to enhance tracking, mapping, and rendering performance in the presence of moving objects. We introduce an uncertainty map, predicted by a shallow multi-layer perceptron and DINOv2 features, to guide dynamic object removal during both tracking and mapping. This uncertainty map enhances dense bundle adjustment and Gaussian map optimization, improving reconstruction accuracy. Our system is evaluated on multiple datasets and demonstrates artifact-free view synthesis. Results showcase WildGS-SLAM's superior performance in dynamic environments compared to state-of-the-art methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/xXuolzFvddQ?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
   
    <!--/ Paper video. -->
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Method</h2>

        <img src="./resources/pipeline_without_mosaic.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>WildGS-SLAM</b> takes a sequence of RGB images as input and simultaneously estimates the camera poses
            while building a 3D Gaussian map of the static scene. Our method is more robust to the dynamic environment due to the uncertainty
            estimation module, where a pretrained DINOv2 model is first used to extract the image features. An uncertainty MLP then utilizes
            the extracted features to predict per-pixel uncertainty. During the tracking, we leverage the predicted uncertainty as the weight in the dense
            bundle adjustment (DBA) layer to mitigate the impact of dynamic distractors. We further use monocular metric depth to facilitate the pose
            estimation. In the mapping module, the predicted uncertainty is incorporated into the rendering loss to update the 3D Gaussian map. Moreover, the uncertainty
            loss is computed in parallel to train the uncertainty MLP. Note that both the uncertainty MLP and 3D Gaussian map are optimized independently, as illustrated by the gradient flow in the gray dashed line. 
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">
          Wild-SLAM Datasets
          <a href="https://huggingface.co/datasets/gradient-spaces/Wild-SLAM" 
             class="is-size-5 ml-3" target="_blank" rel="noopener noreferrer" 
             style="display: inline-flex; align-items: center; background-color: #f5f5f5; padding: 4px 10px; border-radius: 4px;">
            <span class="icon">
              <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" 
                   style="height: 24px; width: auto;">
            </span>
            <span style="margin-left: 5px;">Available on Hugging Face</span>
          </a>
        </h2>
        <div class="content has-text-justified">
          <p style="margin-top: 10px">
            To further assess performance in unconstrained, real-world settings, we introduce the Wild-SLAM Dataset, comprising two subsets: Wild-SLAM MoCap and Wild-SLAM iPhone. 
          </p>
        </div>
        

        <h2 class="title is-4" style="margin-top: -10px">Wild-SLAM MoCap Dataset</h2>
        <img src="./resources/wildslam_mocap.gif" class="center" style="margin-top: -20px; margin-bottom: -20px;">

        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            The Wild-SLAM MoCap Dataset includes 10 RGB-D sequences featuring various moving objects as distractors, specifically designed for dynamic SLAM benchmarking. The sequences are recorded with an Intel RealSense D455 camera with a fixed exposure time. Although WildGS-SLAM works with only monocular inputs, depth images are also included in the dataset to support the evaluation of other RGB-D baselines or future research. The room is equipped with an OptiTrack motion capture system, providing ground truth camera trajectories.
          </p>
        </div>
        
        <h2 class="title is-4" style="margin-top: -10px">Wild-SLAM iPhone Dataset</h2>
        <img src="./resources/wildslam_iphone.gif" class="center" style="margin-top: -20px; margin-bottom: -20px;">

        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            To further assess performance in more unconstrained, real-world scenarios, 
            we collected the Wild-SLAM iPhone Dataset, which comprises 8 non-staged RGB sequences recorded with an iPhone 14 Pro. 
            These sequences comprise 4 outdoor and 4 indoor scenes, 
            showcasing a variety of daily-life activities such as strolling along streets, 
            shopping, navigating a parking garage, and exploring an art museum. 
            Since ground truth trajectories are not available for this dataset, it is used solely for qualitative experiments.
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Results</h2>

        <h3 class="title is-4">Wild-SLAM Mocap</h3>

        <div class="columns is-centered">
          <div class="column">
            <div class="video-container has-text-centered">
              <video id="video1" controls preload="auto" height="100%">
                <source src="./resources/results/stones.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <!-- <p class="caption">First video caption</p> -->
            </div>
          </div>
          <div class="column">
            <div class="video-container has-text-centered">
              <video id="video2" controls preload="auto" height="100%">
                <source src="./resources/results/umbrella.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <!-- <p class="caption">Second video caption</p> -->
            </div>
          </div>
        </div>
        
        <h3 class="title is-5">Reconstruction (from Umbrella sequence)</h3>
        <div class="columns is-centered">
          <div class="column is-10">
            <div class="has-text-centered">
              <iframe 
                id="viewer" 
                width="800" 
                height="500" 
                allow="fullscreen; xr-spatial-tracking" 
                src="https://superspl.at/s?id=7e44cda0&autoplay=false" 
                style="max-width: 100%; border: none;"
              ></iframe>
            </div>
          </div>
        </div>

        <h3 class="title is-4">Wild-SLAM iPhone</h3>

        <!-- <div style="height: 30px;"></div> 
        <h3 class="title is-5">Rendering</h3> -->
        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="replica-rendering">
              <li class="nav-item active">
                <a class="nav-link" onclick="replicaRenderingEvent(0)">room0</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(1)">room1</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(2)">room2</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(3)">office0</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(4)">office1</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(5)">office2</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(6)">office3</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(7)">office4</a>
              </li>
          </ul>
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
              <img src="resources/rendering/replica/room0_nice.jpg" alt="NICE-SLAM">
              <img src="resources/rendering/replica/room0_dim.jpg" alt="DIM-SLAM">
              <img src="resources/rendering/replica/room0_droid.jpg" alt="DROID-SLAM">
              <img src="resources/rendering/replica/room0_ours.png" alt="NICER-SLAM (Ours)">
              <img src="resources/rendering/replica/room0_gt.png" alt="GT">
          </div>
        </div>
        
        <div style="height: 50px;"></div> 
        <h3 class="title is-4">Bonn RGB-D Dynamic Dataset</h3>
        <!-- <div class="content has-text-justified">
          <p>
            Replacing the 2D dilation of 3DGS with an EWA (elliptical weighted average) filter, denoted as 3DGS + EWA, reduces the dilation and erosion artifacts.
            However, it produces high-frequency artifacts when zooming in, while our method is free of such artifacts, as shown in the following comparisons.
          </p>
        </div> -->
        
        <div class="container">
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
              <img src="resources/recon/7scenes/7scenes_office_nice_normal.jpg" alt="NICE-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_nerfslam_normal.jpg" alt="NeRF-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_dim_normal.jpg" alt="DIM-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_droid_normal.jpg" alt="DROID-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_ours_normal.jpg" alt="NICER-SLAM (Ours)">
              <img src="resources/recon/7scenes/7scenes_office_gt_normal.jpg" alt="GT">
          </div>
        </div>
        
        
       

        <!-- <div class="content has-text-centered">
          <video class="video" width="100%" id="xyalias9" loop playsinline autoplay muted src="resources/bonsai_3dgs_ewa_vs_ours.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
          <canvas height=0 class="videoMerge" id="xyalias9Merge"></canvas>
        </div> -->

        <!-- <div class="content has-text-justified">
          <p>
            Here, we show more comparisons with 3DGS + EWA. Both models are trained with downsampled images with factor 8 and render at higher-resolution. 
            GT (Training resolution) is the image we used for training but bilinearly upsampled to higher-resolution for reference and GT (8x resolution) is the real GT image we used for evaluation.
          </p>
        </div> -->

        

        <!-- <br> -->
        <div style="height: 50px;"></div> 
        <h3 class="title is-4">TUM RGB-D Dataset</h3>

        <!-- <h3 class="title is-5">Rendering</h3> -->
        <!-- <div class="container"> -->
          <!-- <ul class="nav nav-tabs nav-fill nav-justified" id="self-rendering">
            <li class="nav-item">
              <a class="nav-link" onclick="sevenScenesReconEvent(0)">room0</a>
            </li>
            <li class="nav-item">
              <a class="nav-link active" onclick="sevenScenesReconEvent(1)">room1</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="sevenScenesReconEvent(2)">room2</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="sevenScenesReconEvent(3)">room3</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="sevenScenesReconEvent(4)">room4</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="sevenScenesReconEvent(5)">office0</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="sevenScenesReconEvent(6)">office1</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="sevenScenesReconEvent(7)">office2</a>
            </li>
        </ul> -->
        
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
              <img src="resources/rendering/self/azure_15_colmap.jpg" alt="COLMAP">
              <img src="resources/rendering/self/azure_15_tandem.jpg" alt="TANDEM">
              <img src="resources/rendering/self/azure_15_nerfslam.jpg" alt="NeRF-SLAM">
              <img src="resources/rendering/self/azure_15_droid.jpg" alt="DROID-SLAM">
              <img src="resources/rendering/self/azure_15_ours.jpg" alt="NICER-SLAM (Ours)">
          </div>
        <!-- </div> -->
        <!-- <div style="height: 50px;"></div>
        <h3 class="title is-5">Reconstruction</h3>

        <div class="b-dics" style="width: 1000px; font-weight: 600;">
          <img src="resources/recon/self/azure_11_colmap_normal.jpg" alt="COLMAP">
          <img src="resources/recon/self/azure_11_tandem_normal.jpg" alt="TANDEM">
          <img src="resources/recon/self/azure_11_nerfslam_normal.jpg" alt="NeRF-SLAM">
          <img src="resources/recon/self/azure_11_droid_normal.jpg" alt="DROID-SLAM">
          <img src="resources/recon/self/azure_11_ours_normal.jpg" alt="NICER-SLAM (Ours)">
      </div> -->

      </div>
    </div>

  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{Zheng2024WildGS,
  author={Zheng, Jianhao and Zhu, Zihan and Bieri, Valentin and Pollefeys, Marc and Peng, Songyou and Armeni Iro},
  title     = {WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments},
  booktitle = {arXiv preprint arXiv:2410.XXXX},
  year      = {2024},
}</code></pre>
  </div>
</section>

<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
     We thank Sayan Deb Sarkar, Tao Sun, Ata Celen, Liyuan Zhu, Emily Steiner, Jikai Jin, Yiming Zhao, 
     Matt VanCleave, Tess Ruby Horowitz Buckley, Stanley Wang for their help in Wild-SLAM data collection.
     We thank Aleesa Pitchamarn Alexander for granting permission to release the data collected from the 
     <a href="https://museum.stanford.edu/exhibitions/spirit-house">Spirit House</a> exhibition. 
     We also thank Aleesa Pitchamarn Alexander, Robert M. and Ruth L. Halperin for curating the exhibition, 
     as well as all the participating artists, particularly Dominique Fung, Stephanie H. Shih, and Tammy Nguyen whose 
     art works are prominently captured in the video data.
  </div>
</section>

<!-- <section class="section" id="References">
  <div class="container is-max-desktop content">

        <h3 class="title is-4">References</h3>
        <div class="content has-text-justified">
          <ul>
            <li>
              <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a>
            </li>
            <li>
              <a href="https://www.cs.umd.edu/~zwicker/publications/EWASplatting-TVCG02.pdf" target="_blank">EWA Splatting</a>
            </li>
          </ul>
        </div>
      </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template. 
            The video comparison with sliding bar is from <a href="https://dorverbin.github.io/refnerf/">Ref-NeRF</a>. 
            The image comparison with sliding bar is from <a href="https://research.nvidia.com/labs/dir/neuralangelo/">Neuralangelo</a>. 
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
